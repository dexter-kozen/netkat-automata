\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,latexsym,amsmath,stmaryrd,dk,dkenv,enumerate}
\usepackage{tikz}
\usepgflibrary{shapes}
\usetikzlibrary{arrows,automata,backgrounds}
\usepackage{bbm}

\usepackage[all]{xy}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\DeclareFontFamily{U}{mathb}{\hyphenchar\font45}
\DeclareFontShape{U}{mathb}{m}{n}{<5> <6> <7> <8> <9> <10> gen * mathb <10.95> mathb10 <12> <14.4> <17.28> <20.74> <24.88> mathb12}{}
\DeclareSymbolFont{mathb}{U}{mathb}{m}{n}
\DeclareMathSymbol\fsmash\mathbin{mathb}{"0C}

\newcommand\den[1]{\llbracket #1\rrbracket}
\newcommand\rsem[1]{[#1]}
\newcommand\lsem[1]{L\den{#1}}
\newcommand\cset[1]{\{#1\}}
\newcommand\Rel{\kw{Rel}}
\newcommand\KL{\kw{Kl}}
\newcommand\KLP{\ensuremath{\KL\,\PP}} 
\newcommand\lam[2]{\lambda{#1}\kern1pt.\kern1pt{#2}}
\newcommand\nf[1]{#1^{\mathrm{nf}}}
\newcommand\CA{\ensuremath{P}}
\newcommand\At{\ensuremath{\mathsf{At}}}
\newcommand\cseq[2]{\pseq{\pseq{#1}\cdots}{#2}}
\renewcommand\smash{\mathrel{\diamond}}
\newcommand\ssum{\mathop{\textstyle\sum}}
\newcommand\sbigcup{\mathop{\textstyle\bigcup}}
\newcommand\pdup{\mathop{\mathsf{dup}}}
\newcommand\One{\mathbf{1}}
\newcommand\Two{\mathbf{2}}
\newcommand\Exp{\mathsf{Exp}}
\newcommand\bval[1]{[#1]}
\renewcommand\star{^{\textstyle *}}
\newcommand\id{\mathsf{id}}
\newcommand\NetHKC[2]{\texttt{NetKATEquiv}(#1,#2)}
\newcommand\pair[2]{\langle #1,#2\rangle}
\renewcommand\powerset[1]{2^{#1}}
\newcommand\JI{\At\cdot(P\cdot\pdup)\star\cdot P}
\newcommand\setJI{2^{\At\cdot P\cdot(\pdup\cdot P)^{\scriptstyle *}}}
\newcommand\funJI{(2^{\At \cdot P})^{(P\cdot\pdup)^{\scriptstyle *}}}
\newcommand\acc{\mathsf{Accept}}
\newcommand\clname{\mathrm{cl}}
\newcommand\cl[1]{\clname(#1)}

\newcommand\repname{R}
\newcommand\repone[1]{\repname(#1)}
\newcommand\rep[2]{\repname(#2)(#1)}
\newcommand\pfun\rightharpoonup
\newcommand\arity[1]{\mathrm{arity}(#1)}

\newcommand\STD{\Delta}
\newcommand\Anti{A}
\newcommand\STDM{\Delta}
\newcommand\Mat[2]{\mathsf{Mat}(#1,#2)}

\begin{document}

A \emph{packet} is a map $\alpha:\{\text{fields}\}\to\{\text{values}\}$. There are a fixed finite number of fields in a packet. Fields are denoted $f,g,\ldots$~. The value of the field $f$ in packet $\alpha$ is denoted $\alpha.f$.

Packets can be modified using a rebinding operator. The packet $\alpha\subst mf$ is obtained by rebinding field $f$ to value $m$ in $\alpha$. Formally,
\begin{align*}
\alpha\subst mf.g = \begin{cases}
\alpha.g & \text{if $f\neq g$ (that is, if $f$ and $g$ are different fields)}\\
m & \text{if $f=g$}.
\end{cases}
\end{align*}

Packets are in one-to-one correspondence with atoms (complete tests). The packet with values $\alpha.f=n_f$ corresponds to the atom (complete test) $\bigwedge_f f=n_f$. We can therefore identify packets with atoms. This allows us to interpret $\alpha$ as either an atom or its corresponding packet, depending on context.

A \emph{packet history} is a nonnull list of packets $\alpha_1::\cdots::\alpha_n$. The \emph{head packet} is $\alpha_1$. Packet histories are denoted $h$.

\subsection*{NFAs}

Apply the Kleene construction to get an NFA $M_e$ from a NetKAT expression $e$. Assume wlog that De Morgan has been applied to tests so that all negations are applied only to primitive tests. Thus edge labels are either assignments $f\leftarrow n$, primitive tests $f = m$ or their negations $f\neq m$, or $\pdup$. Call this alphabet $\Sigma$. We have a nondeterministic automaton $(Q,\tau,S,F)$ where:
\begin{itemize}
\item
$Q$ is a finite set of states
\item
$\tau\subs Q\times\Sigma\times Q$ is the transition relation
\item
$S\subs Q$ are the start states
\item
$F\subs Q$ are the accept states.
\end{itemize}

\subsection*{Transducer Semantics}

Can be viewed operationally or denotationally.

\subsubsection*{Operational View}

Start with a single nonempty packet history placed on a nondeterminstically chosen start state. Now suppose we have a packet history on a state $s$. If $s\in F$, we can nondeterministically decide to stop, in which case we include the current packet history in the output set. Otherwise, we can move along any nondeterministically chosen enabled edge out of $s$, modifying the packet history as determined by the label of the edge. Whether an edge is enabled depends on the label and the current head packet.
\begin{itemize}
\item
Assignment edges are always enabled. If the edge is an assignment edge $s\goesto{f\leftarrow m}{}t$ and the current packet history is $\alpha::h$, then we can move from $s$ to $t$, rebinding the field $f$ of the head packet to the value $m$. The new packet history is $\alpha\subst mf::h$.
\item
Dup edges are always enabled. If the edge is a dup edge $s\goesto{\pdup}{}t$ and the current packet history is
$\alpha::h$, then we can move from $s$ to $t$, duplicating the head packet. The new packet history is $\alpha::\alpha::h$.
\item
A test edge $s\goesto{f=m}{}t$ or $s\goesto{f\neq m}{}t$ is enabled if the test is true for the head packet of the current packet history. If the current packet history is $\alpha::h$, then the edge $s\goesto{f=m}{}t$ is enabled if $\alpha.f=m$ and $s\goesto{f\neq m}{}t$ is enabled if $\alpha.f\neq m$. If the edge is enabled, we can move along the edge to state $t$, but we do not alter the packet history.
\end{itemize}
Let $L(N_e)(h)$ denote the output set starting with input history $h$. This is the the set of packet histories that can ever be ``output'' (can ever occupy a final state) on input $h$. Then $L(M_e):H\to\powerset H$. Note that $L(M_e)(h)$ only depends on the head packet of $h$; thus if $\alpha$ is a single packet, then
\begin{align*}
L(M_e)(\alpha::h) = \set{x::h}{x\in L(M_e)(\alpha)},
\end{align*}
or in other words, $x::h\in L(M_e)(\alpha::h)$ if and only if $x\in L(M_e)(\alpha)$.

\subsubsection*{Denotational View}

We can represent the output set of $L(M_e)(h)$ in terms of a least fixpoint of a monotone map on state labelings of type $\ell:Q\to\powerset H$, ordered by pointwise set inclusion; that is, $\ell\leq\ell'$ if $\ell(s)\subs\ell'(s)$ for all $s\in Q$. The labeling we are interested in is the least labeling $\ell:Q\to\powerset H$ such that:
\begin{itemize}
\item
$h\in \ell(s)$ for all $s\in S$
\item
if $\alpha::h \in \ell(s)$ and $s\goesto{f\leftarrow m}{}t\in\tau$, then $\alpha\subst mf::h \in \ell(t)$
\item
if $\alpha::h \in \ell(s)$ and $s\goesto{\pdup}{}t\in\tau$, then $\alpha::\alpha::h \in \ell(t)$
\item
if $\alpha::h \in \ell(s)$, $s\goesto{f=m}{}t\in\tau$, and $\alpha.f=m$, then $\alpha::h \in \ell(t)$
\item
if $\alpha::h \in \ell(s)$, $s\goesto{f\neq m}{}t\in\tau$, and $\alpha.f\neq m$, then $\alpha::h \in \ell(t)$.
\end{itemize}
Then $L(M_e)(h) = \bigcup_{t\in F}\ell(t)$.

\begin{theorem}
$\den e = L(M_e)$.
\end{theorem}

\subsection*{Language Recognition Semantics for NFAs}

Inputs to the automaton are strings in $\At\cdot(P\cdot\pdup)\star\cdot P$. Such a string $x$ is \emph{accepted} if there is a path from some $s\in S$ to some $t\in F$ with label $y$ such that the inequality $x\leq y$ follows from the axioms of NetKAT. The label of a directed path is the concatenation of the edge labels along the path in order. Let $G(M_e)$ denote the set of accepted strings.

We have overloaded the symbol $G$---recall that it also denotes the inductively defined map from NetKAT expressions to subsets of $\At\cdot(P\cdot\pdup)\star\cdot P$.

\begin{theorem}
$G(e) = G(M_e)$.
\end{theorem}

\subsection*{Relation between Transducer and Language Semantics}

Let $\alpha_i$ be packets, $1\leq i\leq m$. Let $p_i$ be the corresponding complete assignments; that is, $p_i$ is the complete assignment that assigns $f\leftarrow\alpha_i.f$ for all fields $f$.

\begin{theorem}
The following are equivalent:
\begin{enumerate}
\romanize
\item
$\alpha_m::\cdots::\alpha_1 \in L(M_e)(\alpha_0)$
\item
$\alpha_m::\cdots::\alpha_1 \in \den{e}(\alpha_0)$
\item
$\alpha_0 p_1 \pdup p_2 \pdup \cdots \pdup p_m \in G(M_e)$
\item
$\alpha_0 p_1 \pdup p_2 \pdup \cdots \pdup p_m \in G(e)$.
\end{enumerate}
\end{theorem}

\section*{DFAs}

\subsection*{Left-to-Right}

A left-to-right DFA is a coalgebra for the functor $FX = X^{\At\times P}\times 2^{\At\times P}$ with distinguished start state $s\in X$. The structure map is pair of functions
\begin{align*}
\delta &: X\to X^{\At\times P} & \eps &: X\to 2^{\At\times P}.
\end{align*}
We write $\delta_{\alpha p}(t)$ for $\delta(t)(\alpha,p)$ and $\eps_{\alpha p}(t)$ for $\eps(t)(\alpha,p)$, so
\begin{align*}
\delta_{\alpha p} &: X\to X & \eps_{\alpha p} &: X\to 2.
\end{align*}
Inputs to the automaton are strings of the form
\begin{align*}
\alpha p_1\pdup p_2\pdup\cdots\pdup p_m
\end{align*}
in $\At\cdot(P\cdot\pdup)\star\cdot P$.

Intuitively, $\delta_{\alpha p}$ reads $\alpha p\pdup$ from the front of the input string and moves to a new state, and $\eps_{\alpha p}$ accepts if the string ends with $\alpha p$. Formally, acceptance is defined in terms of a predicate $\acc:X\times\At\cdot(P\cdot\pdup)\star\cdot P\to\Two$ coinductively defined by
\begin{align*}
\acc(t,\alpha p\pdup x) &= \acc(\delta_{\alpha p}(t),\alpha_p x)\\
\acc(t,\alpha p) &= \eps_{\alpha p}(t).
\end{align*}
A string $x\in\At\cdot(P\cdot\pdup)\star\cdot P$ is \emph{accepted} by the automaton if $\acc(s,x)$.

\subsection*{Right-to-Left}

A right-to-left DFA is a coalgebra for the functor $FX = X^{P}\times 2^{\At\times P}$ with distinguished start state $s\in X$. The structure map is a pair of functions
\begin{align*}
\delta &: X\to X^{P} & \eps &: X\to 2^{\At\times P}.
\end{align*}
We write $\delta_{\pdup p}(t)$ for $\delta(t)(p)$ and $\eps_{\alpha p}(t)$ for $\eps(t)(\alpha,p)$, so
\begin{align*}
\delta_{\pdup p} &: X\to X & \eps_{\alpha p} &: X\to 2.
\end{align*}
Inputs to the automaton are strings of the form
\begin{align*}
\alpha p_1\pdup p_2\pdup\cdots\pdup p_m
\end{align*}
in $\At\cdot P\cdot(\pdup\cdot P)\star$. Acceptance is defined in terms of a coinductively defined predicate $\acc:X\times\At\cdot P\cdot(\pdup\cdot P)\star\to 2$.
\begin{align*}
\acc(t,x\pdup p) &= \acc(\delta_{\pdup p}(t),x)\\
\acc(t,\alpha p) &= \eps_{\alpha p}(t).
\end{align*}
A string $x\in\At\cdot P\cdot(\pdup\cdot P)\star$ is \emph{accepted} by the automaton if $\acc(s,x)$.

\section*{Conversion to DFAs (L2R)}

\subsection*{Closure}

For NetKAT expression $e$, we define the \emph{closure} of $e$, denoted $\cl e$, to be the smallest set
of terms containing $e$ and closed under the following rules:
\begin{equation}
\begin{array}{c@{\qquad}c@{\qquad}c}
\dfrac{e\in\cl{e_1}}{e\in\cl{e_1+e_2}} & \dfrac{e\in\cl{e_1}}{ee_2\in\cl{e_1e_2}} & \dfrac{e\in\cl{e_1}}{ee_1\star\in\cl{e_1\star}}\\[1em]
\dfrac{e\in\cl{e_2}}{e\in\cl{e_1+e_2}} & \dfrac{e\in\cl{e_2}}{e\in\cl{e_1e_2}} & \dfrac{e\in\cl{b}}{e\in\cl{\bar b}}
\end{array}
\label{eq:cldef}
\end{equation}
For $A$ a set of expressions, define $\cl A = \bigcup_{e\in A} \cl e$.

\begin{lemma}
The operator $\mathrm{cl}$ applied to sets is monotone; that is, if $A\subs B$, then $\cl A\subs\cl B$.
\end{lemma}
\begin{proof}
Obvious from the definition.
\end{proof}

\begin{lemma}
\label{eq:closure}
The operator $\clname$ is a closure operator; that is, $\cl{\cl e} = \cl e$.
\end{lemma}
\begin{proof}
We have $\cl e\subs\cl{\cl e}$, since $e\in\cl e$ and $\clname$ is monotone. For the opposite inclusion,
it follows from the inductive definitions \eqref{eq:cldef} that
\begin{equation}
\begin{array}{r@{\ }lr@{\ }l}
\cl{e_1+e_2} &= \{e_1+e_2\} \cup \cl{e_1} \cup \cl{e_2} & \cl{e_1\star} &= \{e_1\star\} \cup \cl{e_1}e_1\star\\[1ex]
\cl{e_1e_2} &= \{e_1e_2\} \cup \cl{e_1}e_2 \cup \cl{e_2} & \cl{\bar b} &= \{\bar b\} \cup \cl{b},
\end{array}
\label{eq:clprop}
\end{equation}
where $Ae = \set{e'e}{e'\in A}$.
Proceeding by induction,
\begin{align*}
\cl{\cl{e_1+e_2}} &= \cl{\{e_1+e_2\} \cup \cl{e_1} \cup \cl{e_2}} = \cl{\{e_1+e_2\}} \cup \cl{\cl{e_1}} \cup \cl{\cl{e_2}}\\
&= \cl{e_1+e_2} \cup \cl{e_1} \cup \cl{e_2} = \cl{e_1+e_2}\\
\cl{\cl{e_1e_2}} &= \cl{\{e_1e_2\} \cup \cl{e_1}e_2 \cup \cl{e_2}} = \cl{\{e_1e_2\}} \cup \cl{\cl{e_1}e_2} \cup \cl{\cl{e_2}}\\
&= \cl{e_1e_2} \cup \cl{\cl{e_1}}e_2 \cup \cl{e_2} \cup \cl{e_2} = \cl{e_1e_2} \cup \cl{e_1}e_2 \cup \cl{e_2}\\
&= \cl{e_1e_2}\\
\cl{\cl{e_1\star}} &= \cl{\{e_1\star\} \cup \cl{e_1}e_1\star} = \cl{\{e_1\star\}} \cup \cl{\cl{e_1}}e_1\star \cup \cl{e_1\star}\\
&= \cl{e_1\star} \cup \cl{e_1}e_1\star \cup \cl{e_1\star} = \cl{e_1\star}\\
\cl{\cl{\bar b}} &= \cl{\{\bar b\} \cup \cl{b}} = \cl{\{\bar b\}} \cup \cl{\cl{b}} = \cl{\bar b} \cup \cl{b} = \cl{\bar b}.
\end{align*}
\end{proof}

\begin{lemma}
\label{eq:derivlinear}
The set $\cl e$ contains at most $\len e$ elements, where $\len e$ is the
number of subterms of $e$.
\end{lemma}
%\begin{proof}
%Immediate from \eqref{eq:clprop}.
%\end{proof}
%
\subsection*{Coterms}

To define the set-theoretic derivative, it is helpful to view terms coalgebraically as \emph{coterms} (labeled trees) for the signature of abstract NetKAT expressions. The signature of abstract NetKAT expressions is
\begin{align*}
P\cup B\cup\{+,\,\cdot,\,\star,\,\barnone,\,0,\,1,\pdup\},
\end{align*}
where the arities of the elements of $P$ and $B$ are $0$ and those of $+,\,\cdot,\,\star,\,\barnone,\,0,\,1,\,\pdup$ are $2,\,2,\,1,\,1,\,0,\,0,\,0$, respectively.

In general, a \emph{coterm} for an algebraic signature $\Sigma$ with arities $\arity f$, $f\in\Sigma$ is a partial function $e:\omega\star\pfun\Sigma$ with domain of definition $\dom e\subs\omega\star$ such that
\begin{itemize}
\item 
$\dom e$ is nonempty and prefix-closed;
\item
if $\sigma\in\dom e$, then $\sigma i\in\dom e$ iff $i < \arity{e(\sigma)}$.
\end{itemize}
An occurrence of a subterm of $e$ is identified by its position $\sigma\in\dom e$.  The subterm at position $\sigma$ is the coterm $\lambda\tau.e(\sigma\tau)$ with domain $\set\tau{\sigma\tau\in\dom e}$.

There is a one-to-one correspondence between terms in the usual sense and coterms with finite domain. Formally, the coterm corresponding to the term $e$ is the image of $e$ under the unique map from the initial algebra for the signature $\Sigma$ to the final coalgebra for the same signature. Henceforth, we will identify terms with their corresponding coterms under this map, and consider only finite coterms.

A position $\sigma\in\dom e$ is a \emph{leaf} of $e$ if $\sigma$ is a maximal element of $\dom e$ with respect to the prefix relation. The position $\sigma$ is a leaf of $e$ iff $e(\sigma)$ is of arity 0. Let $\ell(e)$ denote the set of leaves of $e$.

\subsection*{Substitution}

We define a substitution operator on coterms as follows. For $\sigma\in\dom e$, the coterm $e\subst d\sigma$ is intuitively the term obtained by substituting $d$ for the subterm of $e$ at position $\sigma$, whatever it may be. Formally, for $\sigma\in\dom e$,
\begin{align*}
\dom{(e\subst d\sigma)} &= (\dom e - \set{\sigma\rho}{\rho\in\omega\star})\cup\set{\sigma\rho}{\rho\in\dom d}\\
e\subst d\sigma(\tau) &= \begin{cases}
d(\rho) & \tau = \sigma\rho\\
e(\tau) & \text{$\sigma$ is not a prefix of $\tau$.}
\end{cases}
\end{align*}
Substitution can also be defined inductively: $e\subst d\eps = d$ for all $e$, $(e_1+e_2)\subst d{0\sigma}=e_1\subst d\sigma + e_2$, $(e_1+e_2)\subst d{1\sigma}=e_1 + e_2\subst d\sigma$, etc.

\subsection*{Representation Map}

The representation is given in terms of a dependent function
\begin{align*}
\repname &: \prod_{e\in\Exp}\Exp^{\dom e} & \repone e &: \dom e\to\Exp
\end{align*}
defined coinductively by
\begin{align*}
\rep{0\sigma}{e_1+e_2} &= \rep\sigma{e_1} & \rep{0\sigma}{e_1e_2} &= \rep\sigma{e_1}\cdot e_2\\
\rep{1\sigma}{e_1+e_2} &= \rep\sigma{e_2} & \rep{1\sigma}{e_1e_2} &= \rep\sigma{e_2}\\
\rep{0\sigma}{e\star} &= \rep\sigma e\cdot e\star & \rep\eps e &= e.
\end{align*}
Notice that a term is included multiplicatively on the right in the definitions of $\rep{0\sigma}{e_1e_2}$ and $\rep{0\sigma}{e\star}$.
One can show by induction that $\dom{\repone e}=\dom e$, and that for any $\sigma\in\dom e$, $\rep\sigma e\in\cl e$.

\subsection*{Set-Theoretic Derivative}

Now we define a set-theoretic derivative for NetKAT and relate it to the syntactic Brzozowski and Antimirov derivatives. Recall the definition of the map $E:\Exp\to\Two^{\At\times P}$:

\begin{gather}
E_{\alpha p}(q) = \bval{q = p} \qquad
E_{\alpha p}(b) = \bval{\alpha_p=\alpha\leq b} \qquad
E_{\alpha p}(\pdup) = 0\nonumber\\
E_{\alpha p}(e_1+e_2) = E_{\alpha p}(e_1)+E_{\alpha p}(e_2) \qquad
E_{\alpha p}(e_1e_2) = \ssum_{q} E_{\alpha q}(e_1)\cdot E_{\alpha_q p}(e_2)\nonumber\\
E_{\alpha p}(e\star) = \bval{\alpha=\alpha_p} + \ssum_{q} E_{\alpha q}(e)\cdot E_{\alpha_q p}(e\star)\label{def:estar}
\end{gather}

The clause \eqref{def:estar} may appear circular, but it is not. It represents a system of $\len\At^2$ equations in $\len\At^2$ unknowns $E_{\alpha p}(e\star)$, one for each choice of $\alpha$ and $p$, for which we seek the least solution.

Because of the one-to-one correspondence between $P$ and $\At$, we can regard $E$ as a map from expressions to $\At\times\At$ Boolean matrices.
\begin{align}
& E:\Exp\to\Two^{\At\times\At} && 
E(e)_{\alpha\beta} = E_{\alpha p_\beta}(e).\label{eq:estar3}
\end{align}
In this view, the equations \eqref{def:estar} say that the matrix $E(e\star)$ is a solution of
\begin{gather}
E(e\star) = I + E(e)\cdot E(e\star),\label{def:estar2} 
\end{gather}
where $I$ is the $\At\times\At$ identity matrix. The least solution of \eqref{def:estar2} is $E(e)\star$, thus
\begin{align}
E(e\star) &= E(e)\star.\label{def:estar3}
\end{align}
These are Boolean matrices, so $E(e)\star$ can be calculated efficiently from $E(e)$ using the Floyd--Warshall algorithm.

The other clauses in the definition of $E$ can also be conveniently expressed in terms of matrix properties:
\begin{gather*}
E(q)_{\alpha\beta} = \bval{q = p_\beta} \qquad
E(b)_{\alpha\beta} = \bval{\beta=\alpha\leq b} \qquad
E(\pdup) = 0\\
E(e_1+e_2) = E(e_1)+E(e_2) \qquad
E(e_1e_2) = E(e_1)\cdot E(e_2).
\end{gather*}
Note that $E(q)$ is the matrix with 1's in column $\beta$ and 0's elsewhere, and $E(b)$ is the diagonal matrix with 1's on the main diagonal in locations corresponding to atoms $\alpha\leq b$ and 0's elsewhere. These properties along with \eqref{def:estar3} say that $E$ can be viewed as a KAT homomorphism $E:\Exp\to\Mat\Two\At$, where $\Mat\Two\At$ is the KAT of $\At\times\At$ Boolean matrices.

Now we define a set-theoretic derivative $\STD$ of type
\begin{align*}
\STD_{\alpha p} &: \prod_{e\in\Exp}2^{\ell(e)} & \STD_{\alpha p}(e) &\subs \ell(e).
\end{align*}
Recall that $\ell(e)\subs\dom e$ is a set of strings in $\omega\star$ specifying the leaves of the term $e$.
The map $\STD_{\alpha p}$ is going to tell us where to apply $\repname$ to obtain the Antimirov derivative.
The map $\STD_{\alpha p}$ is defined inductively by
\begin{align}
\STD_{\alpha p}(e_1+e_2) &= \{0\}\cdot\STD_{\alpha p}(e_1) \cup \{1\}\cdot\STD_{\alpha p}(e_2)\nonumber\\
\STD_{\alpha p}(e_1e_2) &= \{0\}\cdot\STD_{\alpha p}(e_1) \cup \bigcup_{E_{\alpha q}(e_1)=1} \{1\}\cdot\STD_{\alpha_qp}(e_2)\nonumber\\
\STD_{\alpha p}(e\star) &= \{0\}\cdot\STD_{\alpha p}(e) \cup \bigcup_{E_{\alpha q}(e)=1}\STD_{\alpha_qp}(e\star)\label{def:estardiv1}\\
&= \bigcup_{E_{\alpha q}(e^{\scriptstyle *})=1} \{0\}\cdot\STD_{\alpha_qp}(e)\label{def:estardiv2}\\
\STD_{\alpha p}(b) &= \STD_{\alpha p}(q) = \emptyset\nonumber\\
\STD_{\alpha p}(\pdup) &= \begin{cases}
\{\eps\} & \text{if $\alpha=\alpha_p$}\\
\emptyset & \text{if $\alpha\neq\alpha_p$.}\nonumber
\end{cases}
\end{align}
It follows inductively from the definition that $\STD_{\alpha p}(e) \subs \ell(e)$.

Again, the clause \eqref{def:estardiv1} may appear circular, but as above with $E$, it is just a specification of a system of $\len\At^2$ equations in $\len\At^2$ unknowns $\STD_{\alpha p}(e\star)$, one for each choice of $\alpha$ and $p$. These represent subsets of $\ell(e\star)$. We claim that the least solution of this system is given by \eqref{def:estardiv2}. To see this, note that as we did above with $E$, we can regard $\STDM(e)$ as an $\At\times\At$ matrix over $\powerset{\ell(e)}$:
\begin{gather*}
\STDM(e)_{\alpha\beta} = \STD_{\alpha p_\beta}(e).
\end{gather*}
In this view, clause \eqref{def:estardiv1} of the definition just says that the matrix $\STDM(e\star)$ is a solution of
\begin{align}
\STDM(e\star) &= I_0\cdot\STDM(e) + E(e)\cdot\STDM(e\star),\label{eq:estardiv3}
\end{align}
where $+$ is interpreted as componentwise union and $I_0$ is the diagonal matrix with diagonal elements $\{0\}$ and off-diagonal elements $\emptyset$. We have also reused the symbol $E$ to refer to the matrix \eqref{eq:estar3} with 1 replaced by $\{\eps\}$ and $0$ replaced by $\emptyset$. The least solution of \eqref{eq:estardiv3} is 
\begin{align*}
\STDM(e\star) &= E(e)\star\cdot I_0\cdot\STDM(e) = E(e\star)\cdot I_0\cdot\STDM(e),
\end{align*}
which is just a succinct expression of \eqref{def:estardiv2}.

As with $E$, the other clauses in the definition of $\STD$ can also be conveniently expressed in terms of matrices:
\begin{align*}
& \STDM(e_1+e_2) = I_0\cdot\STDM(e_1) + I_1\cdot\STDM(e_2) && \STDM(b) = \STDM(q) = 0\\
& \STDM(e_1e_2) = I_0\cdot\STDM(e_1) + E(e_1)\cdot I_1\cdot\STDM(e_2) && \STDM(\pdup) = I_\eps,
\end{align*}
where $0$ is the zero matrix with all entries $\emptyset$ and $I_a$ is the diagonal matrix with diagonal elements $\{a\}$ and off-diagonal elements $\emptyset$.

\subsection*{Antimirov Derivative}

There is an analog of the Antimirov derivative for NetKAT. Both the Antimirov and Brzozowski derivatives can be defined in terms of $\STD$. The Antimirov derivative is of type
\begin{align*}
\Anti_{\alpha p} : \Exp\to\powerset\Exp
\end{align*}
and is defined inductively as follows:
\begin{align}
\Anti_{\alpha p}(e_1+e_2) &= \Anti_{\alpha p}(e_1) \cup \Anti_{\alpha p}(e_2)\nonumber\\
\Anti_{\alpha p}(e_1e_2) &= \Anti_{\alpha p}(e_1)\cdot\{e_2\} \cup \bigcup_{E_{\alpha q}(e_1)=1}\Anti_{\alpha_q p}(e_2)\nonumber\\
\Anti_{\alpha p}(e\star) &= \Anti_{\alpha p}(e)\cdot\{e\star\} \cup \bigcup_{E_{\alpha q}(e)=1}\Anti_{\alpha_q p}(e\star)\label{def:anti}\\
\Anti_{\alpha p}(b) &= \Anti_{\alpha p}(q) = \emptyset\nonumber\\
\Anti_{\alpha p}(\pdup) &= \begin{cases}
\{\alpha\} & \text{if $\alpha=\alpha_p$}\\
\emptyset & \text{if $\alpha\neq\alpha_p$.}\end{cases}\nonumber
\end{align}
As above, for $\Anti_{\alpha p}(e\star)$, we take the least solution of the system \eqref{def:anti}.
This is done symbolically, using the axioms of KA.

Again, using the one-to-one correspondence between $P$ and $\At$, we can view $A$ as a function $A:\Exp\to\Mat\At{\powerset\Exp}$
with $A(e)_{\alpha\beta}=A_{\alpha p_\beta}(e)$. In this view, the definition takes the following succinct form:
\begin{align*}
\Anti(e_1+e_2) &= \Anti(e_1) + \Anti(e_2)\nonumber\\
\Anti(e_1e_2) &= \Anti(e_1)\cdot I_{\{e_2\}} + E(e_1)\cdot\Anti(e_2)\nonumber\\
\Anti(e\star) &= \Anti(e)\cdot I_{\{e^*\}} + E(e)\cdot\Anti(e\star)\\
&= E(e\star)\cdot\Anti(e)\cdot I_{\{e^*\}}\\
\Anti(b) &= \Anti(q) = 0\nonumber\\
\Anti(\pdup)_{\alpha\beta} &= \begin{cases}
\{\alpha\} & \text{if $\alpha=\beta$}\\
\emptyset & \text{if $\alpha\neq\beta$.}\end{cases}\nonumber
\end{align*}
where $+$ indicates componentwise union.

\begin{lemma}
\label{eq:DDelta}\ 
\begin{enumerate}[{\upshape (i)}]
\item
$\Anti_{\alpha p}(e) = \set{\rep\sigma{e\subst{\alpha_p}\sigma}}{\sigma\in\STD_{\alpha p}(e)}$.
\item
Modulo ACI+, $D_{\alpha p}(e) = \ssum\Anti_{\alpha p}(e)$.
\end{enumerate}
\end{lemma}



The Brzozowski derivative can be defined in terms of $\STD$.
Let ACI+ denote the axioms of associativity, commutativity, and idempotence, plus the axioms $(e_1+e_2)e = e_1e + e_2e$, $0e = 0$, and $1e = e$.

\begin{lemma}
\label{eq:ABDelta}
Modulo ACI+, $D_{\alpha p}(e) = \sum\set{\rep\sigma{e\subst{\alpha_p}\sigma}}{\sigma\in\STD_{\alpha p}(e)}$.
\end{lemma}
\begin{proof}
\begin{align*}
\rep\sigma{e_1\subst{d}\sigma}
&= \rep{0\sigma}{e_1\subst{d}\sigma+e_2} = \rep{0\sigma}{(e_1+e_2)\subst{d}{0\sigma}}
\end{align*}
If $A\subs\ell(e_1)$,
\begin{align*}
\set{\rep\sigma{e_1\subst{d}\sigma}}{\sigma\in A}
&= \set{\rep{0\sigma}{(e_1+e_2)\subst{d}{0\sigma}}}{\sigma\in A}\\
&= \set{\rep{0\sigma}{(e_1+e_2)\subst{d}{0\sigma}}}{0\sigma\in 0\cdot A}\\
&= \set{\rep{\tau}{(e_1+e_2)\subst{\alpha_p}{\tau}}}{\tau\in\STD_{\alpha p}(e_1+e_2)}.
\end{align*}

By induction. Reasoning modulo ACI+,
\begin{align*}
D_{\alpha p}(e_1+e_2) &= D_{\alpha p}(e_1) + D_{\alpha p}(e_2)\\
&= \sum\set{\rep\sigma{e_1\subst{\alpha_p}\sigma}}{\sigma\in\STD_{\alpha p}(e_1)}\\
& \qquad + \sum\set{\rep\sigma{e_2\subst{\alpha_p}\sigma}}{\sigma\in\STD_{\alpha p}(e_2)}\\
&= \sum\set{\rep{0\sigma}{e_1\subst{\alpha_p}\sigma+e_2}}{\sigma\in\STD_{\alpha p}(e_1)}\\
& \qquad + \sum\set{\rep{1\sigma}{e_1+e_2\subst{\alpha_p}\sigma}}{\sigma\in\STD_{\alpha p}(e_2)}\\
&= \sum\set{\rep{0\sigma}{(e_1+e_2)\subst{\alpha_p}{0\sigma}}}{\sigma\in\STD_{\alpha p}(e_1)}\\
& \qquad + \sum\set{\rep{1\sigma}{(e_1+e_2)\subst{\alpha_p}{1\sigma}}}{\sigma\in\STD_{\alpha p}(e_2)}\\
&= \sum\set{\rep{0\sigma}{(e_1+e_2)\subst{\alpha_p}{0\sigma}}}{0\sigma\in 0\cdot\STD_{\alpha p}(e_1)}\\
& \qquad + \sum\set{\rep{1\sigma}{(e_1+e_2)\subst{\alpha_p}{1\sigma}}}{1\sigma\in 1\cdot\STD_{\alpha p}(e_2)}\\
&= \sum\set{\rep{\tau}{(e_1+e_2)\subst{\alpha_p}{\tau}}}{\tau\in\STD_{\alpha p}(e_1+e_2)}.
\end{align*}
%\begin{align*}
%D_{\alpha p\pdup}(e_1e_2) &= D_{\alpha p\pdup}(e_1)\cdot e_2 + \sum_q E_{\alpha q}(e_1)\cdot D_{\alpha_qp\pdup}(e_2)\\
%&= D_{\alpha p\pdup}(e_1)\cdot e_2 + \sum_{E_{\alpha q}(e_1)=1} D_{\alpha_qp\pdup}(e_2)\\
%&= \left(\sum\set{\rep\sigma{e_1}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha p\pdup}(e_1)}\right)\cdot e_2\\
%& \qquad + \sum_{E_{\alpha q}(e_1)=1}\sum\set{\rep\sigma{e_2}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha_qp\pdup}(e_2)}\\
%&= \sum\set{(\rep\sigma{e_1}\cdot e_2)\subst{\alpha_p}X}{\sigma\in\STD_{\alpha p\pdup}(e_1)}\\
%& \qquad + \sum\bigcup_{E_{\alpha q}(e_1)=1}\set{\rep\sigma{e_2}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha_qp\pdup}(e_2)}\\
%&= \sum\set{\rep{0\sigma}{e_1e_2}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha p\pdup}(e_1)}\\
%& \qquad + \sum\bigcup_{E_{\alpha q}(e_1)=1}\set{\rep{1\sigma}{e_1e_2}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha_qp\pdup}(e_2)}\\
%&= \sum\set{\rep{\sigma}{e_1e_2}\subst{\alpha_p}X}{\sigma\in 0\cdot\STD_{\alpha p\pdup}(e_1)}\\
%& \qquad + \sum\bigcup_{E_{\alpha q}(e_1)=1}\set{\rep{\sigma}{e_1e_2}\subst{\alpha_p}X}{\sigma\in 1\cdot\STD_{\alpha_qp\pdup}(e_2)}\\
%&= \sum\set{\rep{\sigma}{e_1e_2}\subst{\alpha_p}X}{\sigma\in (0\cdot\STD_{\alpha p\pdup}(e_1) \cup \bigcup_{E_{\alpha q}(e_1)=1} 1\cdot\STD_{\alpha_qp\pdup}(e_2))}\\
%&= \sum\set{\rep{\sigma}{e_1e_2}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha p\pdup}(e_1e_2)}
%\end{align*}
%For $\star$, we would like to show
%\begin{align*}
%D_{\alpha p\pdup}(e\star) &= \sum\set{\rep\sigma{e\star}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha p\pdup}(e\star)}\\
%&= \sum\set{\rep\sigma{e\star}\subst{\alpha_p}X}{\sigma\in\bigcup_{E_{\alpha q}(e^{\scriptstyle *})=1} 0\cdot\STD_{\alpha_qp\pdup}(e)}\\
%&= \sum_{E_{\alpha q}(e^{\scriptstyle *})=1}\sum\set{\rep\sigma{e\star}\subst{\alpha_p}X}{\sigma\in 0\cdot\STD_{\alpha_qp\pdup}(e)}\\
%&= \sum_{E_{\alpha q}(e^{\scriptstyle *})=1}\sum\set{\rep{0\sigma}{e\star}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha_qp\pdup}(e)}\\
%&= \sum_{E_{\alpha q}(e^{\scriptstyle *})=1}\sum\set{\rep{\sigma}{e}\cdot e\star\subst{\alpha_p}X}{\sigma\in\STD_{\alpha_qp\pdup}(e)}\\
%&= \sum_{E_{\alpha q}(e^{\scriptstyle *})=1}\left(\sum\set{\rep{\sigma}{e}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha_qp\pdup}(e)}\right)\cdot e\star\\
%&= \sum_{E_{\alpha q}(e^{\scriptstyle *})=1}\left(\sum\set{\rep{\sigma}{e}\subst{\alpha_p}X}{\sigma\in\STD_{\alpha_qp\pdup}(e)}\right)\cdot e\star\\
%&= \sum_{E_{\alpha q}(e^{\scriptstyle *})=1}D_{\alpha_qp\pdup}(e)\cdot e\star\\
%\end{align*}
\end{proof}

\end{document}
